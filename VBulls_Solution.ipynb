{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Encontro Modulo 1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BtsL-Rbj1_Kh"},"source":["# <center>Encontro Módulo 1 - Case Churn</center>\n","___"]},{"cell_type":"markdown","metadata":{"id":"diLZ_lCj2ICr"},"source":["## Conteúdo\n","* 0 - [Introdução](#intro) <br>\n","* 4 - [Aquisição dos Dados](#data) <br>\n","* 5 - [Pré-processamento de dados](#clean) <br>\n","* 6 - [Análise Exploratória](#eda) <br>\n","* 7 - [Feature Engineering](#fe) <br>\n","* 8 - [Construção do Modelo](#model) <br>\n","\n","<a id=\"casemod1\"></a>"]},{"cell_type":"markdown","metadata":{"id":"-GvzJCPR2VL7"},"source":["<a id='intro'></a>\n","## 0. Introdução\n","\n","Esse notebook será utilizado como apoio ao case apresentado no encontro do final do módulo 1.\n","\n","O intuito desse notebook é mostrar como fazemos para aplicar o *pipeline* de ciência de dados em um projeto real. Para simplicidade, alguns passos do *pipeline* serão passados de forma bem breve e não exaustiva, apenas para fim de exemplificação. Além disso, utilizaremos de técnicas e conceitos que serão apresentados mais pra frente no nosso curso, então não é esperado que você conheça e entenda 100% do código desse notebook.\n","\n","Como exercício, a medida que você for avançando no curso, volte para esse notebook e tente verificar o que mais poderia ter sido feito em cada etapa, além de tentar entender aqueles passos que não estão claros para você nesse primeiro momento."]},{"cell_type":"markdown","metadata":{"id":"dB4f7wvw4_Tw"},"source":["<a id='data'></a>\n","## 4. Aquisição dos Dados\n","\n","Os dados utilizados nesse notebook estão no arquivo ```bd_churn.txt```. O código abaixo apenas lê o arquivo em um ```DataFrame```, uma estrutura de dados da biblioteca ```pandas```, que é bastante utilizada em ciência de dados. Essa estrutura trata os dados como tabelas, com linhas e colunas, bem parecido com o excel. No próximo módulo teremos uma aula específica para entender melhor sobre esse pacote."]},{"cell_type":"code","metadata":{"id":"Z4gKHdF50vX-"},"source":["import pandas as pd\n","\n","df_churn = pd.read_csv('bd_churn.txt', sep='\\t', decimal='.')\n","df_churn.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1hG9_G2F9GbZ"},"source":["df_churn.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RffF3MQoExye"},"source":["<a id='clean'></a>\n","## 5. Pré-processamento de Dados\n","\n","Como um primeiro passo após o entendimento básico dos dados temos o tratamento deles. Primeiro vamos remover algumas colunas dos dados e depois faremos um tratamento de exemplo. Existem alguns tratamentos diferentes que podemos fazer, mas aqui vamos focar no tratamento de valores nulos. Esse tratamento pode ser feito substituindo os nulos por outros valores ou retirando as linhas que contém nulos. Nesse caso, seguiremos pelo segundo caminho, utilizando o método ```.dropna()```.\n"]},{"cell_type":"code","metadata":{"id":"U_Qr8-3wFivx"},"source":["df_churn = df_churn.drop([\"CUST_ID\", \"START_DT\", \"END_DT\", \"INPUT_DT\", \"ACCT_TYPE\", \n","                          \"CLOSED1\", \"CLOSED2\", \"CLOSED3\", \"DUE_DT1\", \"DUE_DT2\", \"DUE_DT3\", \n","                          \"CHARGE1\", \"CHARGE2\", \"CHARGE3\", \"CH_BEG1\", \"CH_BEG2\", \"CH_BEG3\", \n","                          \"CH_END1\", \"CH_END2\", \"CH_END3\", \"BILL_ST1\", \"BILL_ST2\", \"BILL_ST3\", \n","                          \"LT_PMT1\", \"LT_PMT2\", \"LT_PM3\", \"ADJ1\", \"ADJ2\", \"ADJ3\", \"CR_DT1\",\n","                          \"CR_DT2\", \"CR_DT3\", \"TEN_RAW\"], axis=1)\n","df_churn = df_churn.dropna()\n","df_churn.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ktILCQizukI"},"source":["df_churn.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pIRot9_A9GbJ"},"source":["<a id='eda'></a>\n","## 6. Análise Exploratória\n","\n","### Análise univariada\n","Uma das primeiras ações que tomamos ao ler dados em um ```DataFrame``` (df) é pegar algumas características dele como tamanho, tipos de dado, quantidade de nulos e etc. Na célula anterior já utilizamos o método ```.head()``` para ver as primeiras linhas do nosso df. Vamos então utilizar também o método ```.info()``` para ver tamanho e tipos de dados e o ```.describe()``` para obter informações sobre as colunas numéricas."]},{"cell_type":"code","metadata":{"id":"6VQaUK2G-cYL"},"source":["df_churn.describe()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kK7y680O-gIu"},"source":["### Análises de variáveis\n","\n","Outra tarefa comum na análise de exploratória é entender a nossa variável de interesse (no caso, a coluna **CHURN_FL**) e como ela se relaciona com as demais.\n","\n","Vamos começar entendendo a taxa de *churn* na nossa base. Dado que a variável de interesse é uma flag se aquele cliente deu *churn* ou não, a taxa nada mais é do que a média dessa variável. Substitua a lacuna pelo nome da coluna para calcular sua média no código abaixo."]},{"cell_type":"code","metadata":{"id":"KM0p_e0NBFai"},"source":["print('A taxa de churn é:', df_churn[\"CHURN_FL\"].mean())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pe3-EGd5BwTC"},"source":["Agora vamos ver como essa taxa se comporta de acordo com outras variáveis dos nossos dados. Apenas para exemplo, vamos analisar o *churn* contra duas variáveis (uma numérica e outra categórica), mas em um projeto analisaríamos todas. Você pode tentar trocar as variáveis do exemplo por outras e ver se funciona, mas eventualmente será necessário algumas alterações para melhorar a visualização."]},{"cell_type":"code","metadata":{"id":"TqDB5YBeCMxD"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","sns.boxplot(data=df_churn,\n","            x='CHURN_FL',\n","            y='AGE',\n","            palette=\"colorblind\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9CUfO0lhp3ey"},"source":["sns.kdeplot(data=df_churn,\n","            x=\"AGE\",\n","            hue=\"CHURN_FL\",\n","            common_norm=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORCRCvzObmrp"},"source":["sns.barplot(data=df_churn,\n","            x=\"CREDIT_CLASS\",\n","            y=\"CHURN_FL\",\n","            hue=\"GENDER\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zi9IfVZ50rOu"},"source":["<a id='fe'></a>\n","## 7. Feature Engineering\n","\n"]},{"cell_type":"code","metadata":{"id":"9EA_ufYl09zR"},"source":["# seleciona colunas categoricas\n","object_cols = df_churn.select_dtypes(include='object').columns.values\n","object_cols"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IjhzUd_I1wfR"},"source":["# mostra valores distintos dessas colunas\n","for col in object_cols:\n","  print(col, df_churn[col].unique())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wbtscp3725F5"},"source":["# cria variaveis dummies\n","df_churn = pd.concat([df_churn.drop(object_cols, axis=1),\n","                      pd.get_dummies(df_churn[object_cols], prefix=object_cols)], axis=1)\n","print(df_churn.shape)\n","df_churn.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UThFZ5vsbyU3"},"source":["df_churn.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N5JH3-niChZg"},"source":["<a id='model'></a>\n","## 8. Construção do Modelo\n","\n","### Separação de treino e teste\n","\n","Para começar, vamos separar nossos dados em treino e teste. Essa é uma etapa que deve ser feita em todos os modelos supervisionados que você for fazer daqui pra frente, para garantir a qualidade do modelo. Basicamente, aplicamos as técnicas de *machine learning* na base de treino e verificamos os resultados na base de teste para garantir que não há *overfitting*. O código abaixo separa os dados com a função ```train_test_split``` do ```sklearn```, mantendo a mesma proporção da sua variável resposta em ambos os *datasets*."]},{"cell_type":"code","metadata":{"id":"-pUo3p-IKRzH"},"source":["from sklearn.model_selection import train_test_split\n","\n","X = df_churn.drop(\"CHURN_FL\", axis=1).values\n","y = df_churn[\"CHURN_FL\"].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2404)\n","\n","print('X_train', X_train.shape)\n","print('X_test', X_test.shape)\n","print('y_train', y_train.shape)\n","print('y_test', y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5NY2mh45LwTd"},"source":["Vamos de fato à criação do modelo agora. Para exemplo, vamos usar 3 técnicas de classificação apresentadas no notebook de introdução ao *machine learning*.\n","\n","### Árvore de Decisão"]},{"cell_type":"code","metadata":{"id":"EW3fV355L5F_"},"source":["from sklearn.tree import DecisionTreeClassifier, plot_tree\n","from sklearn.metrics import confusion_matrix\n","\n","tree = DecisionTreeClassifier(max_depth=4)\n","tree.fit(X_train, y_train)\n","\n","y_pred_tree = tree.predict(X_test)\n","y_prob_pred_tree = [x[1] for x in tree.predict_proba(X_test)]\n","\n","print(confusion_matrix(y_test, y_pred_tree))\n","\n","plt.figure(figsize=(20,12))\n","plot_tree(tree, fontsize=8)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4xcu5tzoNkEI"},"source":["### Regressão Logística"]},{"cell_type":"code","metadata":{"id":"NCGDe_EbN_3u"},"source":["from sklearn.linear_model import LogisticRegression\n","\n","logreg = LogisticRegression(max_iter=1000)\n","logreg.fit(X_train, y_train)\n","\n","y_pred_logreg = logreg.predict(X_test)\n","y_prob_pred_logreg = [x[1] for x in logreg.predict_proba(X_test)]\n","\n","print(confusion_matrix(y_test, y_pred_logreg))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hnwM36rkN1O5"},"source":["### k-vizinhos mais próximos (k-Nearest Neighbors/k-NN)"]},{"cell_type":"code","metadata":{"id":"V7MHkVK3OTcG"},"source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","knn = KNeighborsClassifier(n_neighbors=3)\n","knn.fit(X_train, y_train)\n","\n","y_pred_knn = knn.predict(X_test)\n","y_prob_pred_knn = [x[1] for x in knn.predict_proba(X_test)]\n","\n","print(confusion_matrix(y_test, y_pred_knn))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C8_hBxeZPIOg"},"source":["<a id='eval'></a>\n","### Avaliação dos Modelos\n","\n","Já vimos na criação dos modelos uma métrica de avaliação, a matriz de confusão. Porém, essa não é a melhor métrica para avaliação dos modelos de classificação. Entraremos mais a fundo nesse tema mais pra frente, mas trazemos aqui a a curva ROC e a área sob a curva."]},{"cell_type":"code","metadata":{"id":"RMEeUzXCMr8B"},"source":["from sklearn.metrics import roc_curve, auc\n","\n","fpr_tree, tpr_tree, thresholds_tree = roc_curve(y_test, y_prob_pred_tree)\n","auc_tree = auc(fpr_tree, tpr_tree)\n","fpr_logreg, tpr_logreg, thresholds_logreg = roc_curve(y_test, y_prob_pred_logreg)\n","auc_logreg = auc(fpr_logreg, tpr_logreg)\n","fpr_knn, tpr_knn, thresholds_knn = roc_curve(y_test, y_prob_pred_knn)\n","auc_knn = auc(fpr_knn, tpr_knn)\n","\n","plt.figure()\n","plt.plot(fpr_tree, tpr_tree, color='blue', label='ROC curve tree (area = %0.2f)' % auc_tree)\n","plt.plot(fpr_logreg, tpr_logreg, color='red', label='ROC curve logreg (area = %0.2f)' % auc_logreg)\n","plt.plot(fpr_knn, tpr_knn, color='green', label='ROC curve knn (area = %0.2f)' % auc_knn)\n","plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Curva ROC')\n","plt.legend(loc=\"lower right\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kx6Ho3Pd5Dzw"},"source":[""],"execution_count":null,"outputs":[]}]}